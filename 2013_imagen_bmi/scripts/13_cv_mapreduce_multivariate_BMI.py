# -*- coding: utf-8 -*-
"""
Created on Mon May 26 13:33:13 2014

@author: hl237680
"""

# -*- coding: utf-8 -*-
import os
import json
import numpy as np
import pandas as pd
import tables
import sys
sys.path.append('/home/hl237680/gits/pylearn-parsimony')     #add pathway en dur
import parsimony.estimators as estimators
#from sklearn.linear_model import ElasticNet
from sklearn.cross_validation import KFold
from sklearn.metrics import r2_score
sys.path.append('/home/hl237680/gits/scripts/2013_imagen_bmi/scripts/')     #add pathway en dur
import bmi_utils



##############
# Parameters #
##############

# Input data
BASE_PATH = '/neurospin/brainomics/2013_imagen_bmi/'
DATA_PATH = os.path.join(BASE_PATH, 'data')
IMAGES_FILE = os.path.join(DATA_PATH, 'smoothed_images.hdf5')
SNPS_FILE = os.path.join(DATA_PATH, 'SNPs.csv')
BMI_FILE = os.path.join(DATA_PATH, 'BMI.csv')

# Shared data
BASE_SHARED_DIR = "/neurospin/tmp/brainomics"
SHARED_DIR = os.path.join(BASE_SHARED_DIR, 'bmi_cache')
if not os.path.exists(SHARED_DIR):
    os.makedirs(SHARED_DIR)




##############################################################################
def load_globals(config):
    import mapreduce as GLOBAL  # access to global variables
    print "start load_globals"
    GLOBAL.DATA = GLOBAL.load_data(config["data"])
    print "finished load_globals"

def resample(config, resample_nb):
    import mapreduce as GLOBAL  # access to global variables
    resample = config["resample"][resample_nb]    
    print "reslicing %d" %resample_nb
    GLOBAL.DATA_RESAMPLED = {k: [GLOBAL.DATA[k][idx, ...] for idx in resample]
                            for k in GLOBAL.DATA}
    print "done reslicing %d" %resample_nb                        

## User map/reduce functions
def mapper(key, output_collector):
    import mapreduce as GLOBAL # access to global variables (GLOBAL.DATA)
    alpha, l1_ratio = key[0], key[1]
    # mod = ElasticNet(alpha=key[0], l1_ratio=key[1])
    print "i am a work that works"
    #mod = estimators.ElasticNet(alpha*l1_ratio, penalty_start = 1, mean = True)
    mod = estimators.ElasticNet(alpha*l1_ratio, penalty_start = 11, mean = True)     #since we residualize BMI with 2 categorical covariables (8 columns) and 2 ordinal variables
    z_pred = mod.fit(GLOBAL.DATA_RESAMPLED["X"][0], GLOBAL.DATA_RESAMPLED["z"][0]).predict(GLOBAL.DATA_RESAMPLED["X"][1])
    output_collector.collect(key, dict(z_pred=z_pred, z_true=GLOBAL.DATA_RESAMPLED["z"][1]), beta=mod.beta)

def reducer(key, values):
    # values are OutputCollerctors containing a path to the results.
    # load return dict correspondning to mapper ouput. they need to be loaded.
    values = [item.load() for item in values]
    z_true = np.concatenate([item["z_true"].ravel() for item in values])
    z_pred = np.concatenate([item["z_pred"].ravel() for item in values])
    return dict(param=key, r2=r2_score(z_true, z_pred))


# SNPs and BMI
def load_data(cache):
    if not(cache):
#        SNPs = pd.io.parsers.read_csv(os.path.join(DATA_PATH, "SNPs.csv"), dtype='float64', index_col=0).as_matrix()
        BMI = pd.io.parsers.read_csv(os.path.join(DATA_PATH, "BMI.csv"), index_col=0).as_matrix()
        
        covariate = pd.io.parsers.read_csv(os.path.join(DATA_PATH, "covariate.csv")).as_matrix()   #covar.csv generated by R-code "covariate_test.R"
        BMI_residualized = np.concatenate((covariate, BMI), axis=1) #residualized BMI using gender, imaging center city, tiv_gaser and mean pds status covariates
        
        h5file = tables.openFile(IMAGES_FILE)
        masked_images = bmi_utils.read_array(h5file, "/standard_mask/residualized_images_gender_center_TIV_pds")    #images already masked
        print "Data loaded"
        X = masked_images
#        Y = SNPs
#        z = BMI
        z = BMI_residualized
        np.save(os.path.join(SHARED_DIR, "X.npy"), X)
#        np.save(os.path.join(SHARED_DIR, "Y.npy"), Y)
        np.save(os.path.join(SHARED_DIR, "z.npy"), z)
        h5file.close()
        print "Data saved"
    else:
        X = np.load(os.path.join(SHARED_DIR, "X.npy"))        
#        Y = np.load(os.path.join(SHARED_DIR, "Y.npy"))
        z = np.load(os.path.join(SHARED_DIR, "z.npy"))        
        print "Data read from cache"
    return X, z     #X, Y, z



if __name__ == "__main__":
    WD = "/neurospin/tmp/brainomics/bmi_imagesPL"
    if not os.path.exists(WD): os.makedirs(WD)

    #############################################################################
    ## Get data
    X, z = load_data(False)   #X, Y, z = load_data(True)
    n, p = X.shape
#    X = np.random.rand(n, p)
#    beta = np.random.rand(p, 1)
#    y = np.dot(X, beta)
    np.save(os.path.join(WD, 'X.npy'), np.hstack((np.ones((z.shape[0],1)),X)))
    np.save(os.path.join(WD, 'z.npy'), z)
    
    #############################################################################
    ## Create config file
    cv = [[tr.tolist(), te.tolist()] for tr,te in KFold(n, n_folds=5)]
    params = [[alpha, l1_ratio] for alpha in [0.0009, 0.001] for l1_ratio in np.arange(0.1, 0.4, .1)]
    user_func_filename = os.path.abspath(__file__)

    config = dict(data=dict(X=os.path.join(WD, "X.npy"),
                            z=os.path.join(WD, "z.npy")),
                  params=params,
                  map_output=os.path.join(WD, "results"),
                  user_func=user_func_filename,
                  resample=cv,
                  ncore=2,
                  reduce_input=os.path.join(WD, "results/*/*"),
                  reduce_group_by=os.path.join(WD, "results/.*/(.*)"))
    json.dump(config, open(os.path.join(WD, "config.json"), "w"))

    #############################################################################
    print "# Run Locally:"
    print "# Map"   
    print "mapreduce.py -m %s/config.json --ncore 2" % WD
    
    #############################################################################
    print "# Reduce"
    print "mapreduce.py -r %s/config.json" % WD
